{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b48958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
       "    if (use_tabs === undefined) {\n",
       "        use_tabs = true; \n",
       "    }\n",
       "\n",
       "    // apply setting to all current CodeMirror instances\n",
       "    IPython.notebook.get_cells().map(\n",
       "        function(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
       "    );\n",
       "    // make sure new CodeMirror instances created in the future also use this setting\n",
       "    CodeMirror.defaults.indentWithTabs=use_tabs;\n",
       "\n",
       "    };\n",
       "\n",
       "IPython.tab_as_tab_everywhere()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "    if (use_tabs === undefined) {\n",
    "        use_tabs = true; \n",
    "    }\n",
    "\n",
    "    // apply setting to all current CodeMirror instances\n",
    "    IPython.notebook.get_cells().map(\n",
    "        function(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "    );\n",
    "    // make sure new CodeMirror instances created in the future also use this setting\n",
    "    CodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\n",
    "    };\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab18958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "/tmp/ipykernel_995395/1311010.py:121: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = cm.get_cmap('tab10', 10)  # Grayscale color map\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Device  StdDev Ports Port Category    StdDev ID  \\\n",
      "0               Wyze_camera    7839.19839     Excellent    188.10117   \n",
      "1         alexa_swan_kettle   16288.95114     Excellent  17311.11043   \n",
      "2          arlo_camera_pro4     127.04026          Poor      0.04335   \n",
      "3                arlo_chime   19419.84077     Excellent  19359.94119   \n",
      "4               belkin_plug    1115.52662          Good   3643.14526   \n",
      "5   blurams_security_camera    8949.05047     Excellent   5010.94474   \n",
      "6              bose_speaker    5373.70860     Excellent  17632.52664   \n",
      "7                eufy_chime    8674.98227     Excellent     14.68451   \n",
      "8          furbo_dog_camera    8359.88165     Excellent  19464.92892   \n",
      "9            ring_chime_pro    8968.04164     Excellent   8217.52478   \n",
      "10      simplisafe_doorbell    7412.65275     Excellent  18032.76627   \n",
      "11            sonos_speaker    6283.85530     Excellent  20528.24133   \n",
      "12          tapo_plug110_33   17455.52603     Excellent  19151.35361   \n",
      "13           tapo_plug110_8   19322.39006     Excellent  12711.07402   \n",
      "14        vtech_baby_camera    8055.71711     Excellent    438.00457   \n",
      "15          wyze_cam_pan_v2    8051.83485     Excellent    206.38829   \n",
      "\n",
      "      ID Category Port Color ID Color  \n",
      "0            Poor      green      red  \n",
      "1       Excellent      green    green  \n",
      "2   No randomness        red     gray  \n",
      "3       Excellent      green    green  \n",
      "4            Good       blue     blue  \n",
      "5       Excellent      green    green  \n",
      "6       Excellent      green    green  \n",
      "7            Poor      green      red  \n",
      "8       Excellent      green    green  \n",
      "9       Excellent      green    green  \n",
      "10      Excellent      green    green  \n",
      "11      Excellent      green    green  \n",
      "12      Excellent      green    green  \n",
      "13      Excellent      green    green  \n",
      "14           Good      green     blue  \n",
      "15           Poor      green      red  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Sample input text\n",
    "input_text = \"\"\"\n",
    "Dataset loaded from pickle at Wyze_camera.pkl\n",
    "stddev_ports = 7839.19839 Excellent randomization (stdev 7839.20 bits 14.73)\n",
    "stddev_id    = 188.10117 Poor randomization (stdev 188.10 bits 9.35)\n",
    "Dataset loaded from pickle at alexa_swan_kettle.pkl\n",
    "stddev_ports = 16288.95114 Excellent randomization (stdev 16288.95 bits 15.78)\n",
    "stddev_id    = 17311.11043 Excellent randomization (stdev 17311.11 bits 15.87)\n",
    "Dataset loaded from pickle at arlo_camera_pro4.pkl\n",
    "stddev_ports = 127.04026 Poor randomization (stdev 127.04 bits 8.78)\n",
    "stddev_id    = 0.04335 No randomness\n",
    "Dataset loaded from pickle at arlo_chime.pkl\n",
    "stddev_ports = 19419.84077 Excellent randomization (stdev 19419.84 bits 16.04)\n",
    "stddev_id    = 19359.94119 Excellent randomization (stdev 19359.94 bits 16.03)\n",
    "Dataset loaded from pickle at belkin_plug.pkl\n",
    "stddev_ports = 1115.52662 Good randomization (stdev 1115.53 bits 11.91)\n",
    "stddev_id    = 3643.14526 Good randomization (stdev 3643.15 bits 13.62)\n",
    "Dataset loaded from pickle at blurams_security_camera.pkl\n",
    "stddev_ports = 8949.05047 Excellent randomization (stdev 8949.05 bits 14.92)\n",
    "stddev_id    = 5010.94474 Excellent randomization (stdev 5010.94 bits 14.08)\n",
    "Dataset loaded from pickle at bose_speaker.pkl\n",
    "stddev_ports = 5373.70860 Excellent randomization (stdev 5373.71 bits 14.18)\n",
    "stddev_id    = 17632.52664 Excellent randomization (stdev 17632.53 bits 15.90)\n",
    "Dataset loaded from pickle at eufy_chime.pkl\n",
    "stddev_ports = 8674.98227 Excellent randomization (stdev 8674.98 bits 14.87)\n",
    "stddev_id    = 14.68451 Poor randomization (stdev 14.68 bits 5.67)\n",
    "Dataset loaded from pickle at furbo_dog_camera.pkl\n",
    "stddev_ports = 8359.88165 Excellent randomization (stdev 8359.88 bits 14.82)\n",
    "stddev_id    = 19464.92892 Excellent randomization (stdev 19464.93 bits 16.04)\n",
    "Dataset loaded from pickle at ring_chime_pro.pkl\n",
    "stddev_ports = 8968.04164 Excellent randomization (stdev 8968.04 bits 14.92)\n",
    "stddev_id    = 8217.52478 Excellent randomization (stdev 8217.52 bits 14.80)\n",
    "Dataset loaded from pickle at simplisafe_doorbell.pkl\n",
    "stddev_ports = 7412.65275 Excellent randomization (stdev 7412.65 bits 14.65)\n",
    "stddev_id    = 18032.76627 Excellent randomization (stdev 18032.77 bits 15.93)\n",
    "Dataset loaded from pickle at sonos_speaker.pkl\n",
    "stddev_ports = 6283.85530 Excellent randomization (stdev 6283.86 bits 14.41)\n",
    "stddev_id    = 20528.24133 Excellent randomization (stdev 20528.24 bits 16.12)\n",
    "Dataset loaded from pickle at tapo_plug110_33.pkl\n",
    "stddev_ports = 17455.52603 Excellent randomization (stdev 17455.53 bits 15.88)\n",
    "stddev_id    = 19151.35361 Excellent randomization (stdev 19151.35 bits 16.02)\n",
    "Dataset loaded from pickle at tapo_plug110_8.pkl\n",
    "stddev_ports = 19322.39006 Excellent randomization (stdev 19322.39 bits 16.03)\n",
    "stddev_id    = 12711.07402 Excellent randomization (stdev 12711.07 bits 15.42)\n",
    "Dataset loaded from pickle at vtech_baby_camera.pkl\n",
    "stddev_ports = 8055.71711 Excellent randomization (stdev 8055.72 bits 14.77)\n",
    "stddev_id    = 438.00457 Good randomization (stdev 438.00 bits 10.57)\n",
    "Dataset loaded from pickle at wyze_cam_pan_v2.pkl\n",
    "stddev_ports = 8051.83485 Excellent randomization (stdev 8051.83 bits 14.77)\n",
    "stddev_id    = 206.38829 Poor randomization (stdev 206.39 bits 9.48)\n",
    "\"\"\"\n",
    "\n",
    "# Parsing the text to extract device names, standard deviations, and categories\n",
    "device_data = []\n",
    "lines = input_text.strip().split(\"\\n\")\n",
    "\n",
    "for i in range(0, len(lines), 3):\n",
    "\tdevice_name = re.search(r'at (.+?)\\.pkl', lines[i]).group(1)\n",
    "\tstddev_ports = float(re.search(r'stddev_ports = ([\\d.]+)', lines[i+1]).group(1))\n",
    "\tcategory_ports = re.search(r'(Excellent|Good|Poor) randomization', lines[i+1]).group(1)\n",
    "\tstddev_id = float(re.search(r'stddev_id\\s+=\\s+([\\d.]+)', lines[i+2]).group(1))\n",
    "\tcategory_id = re.search(r'(Excellent|Good|Poor|No randomness)', lines[i+2]).group(1)\n",
    "\n",
    "\tdevice_data.append((device_name, stddev_ports, category_ports, stddev_id, category_id))\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(device_data, columns=['Device', 'StdDev Ports', 'Port Category', 'StdDev ID', 'ID Category'])\n",
    "\n",
    "# Define colors based on categories\n",
    "color_map = {\n",
    "\t\"Excellent\": \"green\",\n",
    "\t\"Good\": \"blue\",\n",
    "\t\"Poor\": \"red\",\n",
    "\t\"No randomness\": \"gray\"\n",
    "}\n",
    "\n",
    "df['Port Color'] = df['Port Category'].map(color_map)\n",
    "df['ID Color'] = df['ID Category'].map(color_map)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# # Plot standard deviation of source ports\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(df['Device'], df['StdDev Ports'], color=df['Port Color'])\n",
    "# plt.xlabel('Device Name')\n",
    "# plt.ylabel('Standard Deviation of Source Ports')\n",
    "# # plt.title('Standard Deviation of Source Ports per Device')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.legend(handles=[plt.Rectangle((0,0),1,1, color=color_map[c]) for c in color_map.keys()], labels=color_map.keys())\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"stddev_ports_plot.pdf\")\n",
    "# plt.close()\n",
    "\n",
    "# # Plot standard deviation of DNS transaction IDs\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(df['Device'], df['StdDev ID'], color=df['ID Color'])\n",
    "# plt.xlabel('Device Name')\n",
    "# # plt.ylabel('Standard Deviation of DNS Transaction IDs')\n",
    "# # plt.title('Standard Deviation of DNS Transaction IDs per Device')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.legend(handles=[plt.Rectangle((0,0),1,1, color=color_map[c]) for c in color_map.keys()], labels=color_map.keys())\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"stddev_id_plot.pdf\")\n",
    "# plt.close()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Settings\n",
    "bar_width_inches = 3\n",
    "bar_height_inches = 2.2\n",
    "\n",
    "# Hatch and color setup\n",
    "hatches = ['/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "colors = cm.get_cmap('tab10', 10)  # Grayscale color map\n",
    "\n",
    "# === Source Ports Plot ===\n",
    "plt.figure(figsize=(bar_width_inches, bar_height_inches))\n",
    "df2 = df[df[\"Port Category\"] != \"Excellent\"]\n",
    "bars = plt.bar(df2['Device'], df2['StdDev Ports'],\n",
    "\t\t\t   edgecolor='black')\n",
    "\n",
    "# Apply hatch + color\n",
    "for i, bar in enumerate(bars):\n",
    "\tbar.set_hatch(hatches[i % len(hatches)])\n",
    "\tbar.set_facecolor(colors(i % 10))  # Cycle through grayscale\n",
    "\n",
    "plt.xlabel('Device Name', fontsize=10)\n",
    "plt.ylabel(r'$\\sigma$ (Source Ports)', fontsize=10)\n",
    "plt.xticks(rotation=60, ha='right', fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.tight_layout(pad=0.5)\n",
    "plt.savefig(\"stddev_ports_plot.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# === Transaction IDs Plot ===\n",
    "plt.figure(figsize=(bar_width_inches, bar_height_inches))\n",
    "df2 = df[df[\"ID Category\"] != \"Excellent\"]\n",
    "bars = plt.bar(df2['Device'], df2['StdDev ID'],\n",
    "\t\t\t   edgecolor='black')\n",
    "\n",
    "# Apply hatch + color\n",
    "for i, bar in enumerate(bars):\n",
    "\tbar.set_hatch(hatches[i % len(hatches)])\n",
    "\tbar.set_facecolor(colors(i % 10))\n",
    "\n",
    "plt.xlabel('Device Name', fontsize=10)\n",
    "plt.ylabel(r'$\\sigma$ (Transaction IDs)', fontsize=10)\n",
    "plt.xticks(rotation=60, ha='right', fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "# plt.tight_layout(pad=0.5)\n",
    "plt.savefig(\"stddev_id_plot.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e679e60f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from pickle at ../../iot_data_baseline.pkl\n",
      "        Device Name                                        Packet JSON\n",
      "0  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "1  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "2  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "3  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "4  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "class IoTPcapReader:\n",
    "\tdef __init__(self, dataset_folder: str):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize the IoTPcapReader with the folder path.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tdataset_folder (str): The path to the dataset folder containing device subfolders.\n",
    "\t\t\"\"\"\n",
    "\t\tself.dataset_folder = dataset_folder\n",
    "\t\tself.global_dataframe = pd.DataFrame()\n",
    "\t\tself.dns_dataframe = pd.DataFrame()\n",
    "\n",
    "\tdef _run_tshark(self, file_path: str) -> list:\n",
    "\t\t\"\"\"\n",
    "\t\tRun tshark command to extract full packet details in JSON format.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tfile_path (str): Path to the pcap file.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tlist: A list of complete packet details as dictionaries.\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\tcmd = [\"tshark\", \"-r\", file_path, \"-T\", \"json\"]\n",
    "\t\t\tresult = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "\t\t\tpackets = json.loads(result.stdout)\n",
    "\t\t\treturn packets\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error running tshark on {file_path}: {e}\")\n",
    "\t\t\treturn []\n",
    "\n",
    "\tdef _parse_packets(self, packets: list, device_name: str):\n",
    "\t\t\"\"\"\n",
    "\t\tParse full packet JSON data and add it to the dataframe.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tpackets (list): List of packet details as dictionaries.\n",
    "\t\t\tdevice_name (str): Name of the IoT device.\n",
    "\t\t\"\"\"\n",
    "\t\tdata = []\n",
    "\n",
    "\t\tfor packet in packets:\n",
    "\t\t\tif \"_source\" in packet and \"layers\" in packet[\"_source\"]:\n",
    "\t\t\t\trow = {\n",
    "\t\t\t\t\t'Device Name': device_name,\n",
    "\t\t\t\t\t'Packet JSON': json.dumps(packet)  # Store the full JSON as a string\n",
    "\t\t\t\t}\n",
    "\t\t\t\tdata.append(row)\n",
    "\n",
    "\t\ttemp_df = pd.DataFrame(data)\n",
    "\t\tself.global_dataframe = pd.concat([self.global_dataframe, temp_df], ignore_index=True)\n",
    "\n",
    "\tdef _read_pcap_file(self, file_path: str, device_name: str):\n",
    "\t\t\"\"\"\n",
    "\t\tRead the contents of a pcap file and extract frame information using tshark.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tfile_path (str): Path to the pcap file.\n",
    "\t\t\tdevice_name (str): Name of the IoT device associated with the pcap file.\n",
    "\t\t\"\"\"\n",
    "\t\tpackets = self._run_tshark(file_path)\n",
    "\t\tif packets:\n",
    "\t\t\tself._parse_packets(packets, device_name)\n",
    "\n",
    "\tdef read_all_pcap_files(self):\n",
    "\t\t\"\"\"\n",
    "\t\tRead all pcap files from all device subfolders and store the data in a global dataframe.\n",
    "\t\t\"\"\"\n",
    "\t\tfor device_folder in os.listdir(self.dataset_folder):\n",
    "\t\t\tdevice_path = os.path.join(self.dataset_folder, device_folder)\n",
    "\t\t\tif os.path.isdir(device_path):\n",
    "\t\t\t\tfor file_name in os.listdir(device_path):\n",
    "\t\t\t\t\tif file_name.endswith('.pcap'):\n",
    "\t\t\t\t\t\tfile_path = os.path.join(device_path, file_name)\n",
    "\t\t\t\t\t\tprint(f\"Reading file: {file_path}\")\n",
    "\t\t\t\t\t\tself._read_pcap_file(file_path, device_folder)\n",
    "\n",
    "\tdef save_as_pickle(self, output_file: str):\n",
    "\t\t\"\"\"\n",
    "\t\tSave the global dataframe as a pickle file.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\toutput_file (str): The output pickle file path.\n",
    "\t\t\"\"\"\n",
    "\t\twith open(output_file, 'wb') as f:\n",
    "\t\t\tpickle.dump(self.global_dataframe, f)\n",
    "\t\tprint(f\"Dataset saved as pickle at {output_file}\")\n",
    "\n",
    "\tdef load_pickle(self, pickle_file: str):\n",
    "\t\t\"\"\"\n",
    "\t\tLoad the dataset from a pickle file.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tpickle_file (str): The path to the pickle file.\n",
    "\t\t\"\"\"\n",
    "\t\twith open(pickle_file, 'rb') as f:\n",
    "\t\t\tself.global_dataframe = pickle.load(f)\n",
    "\t\tprint(f\"Dataset loaded from pickle at {pickle_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# Example usage:\n",
    "\tdataset_folder_path = '../../baseline'\n",
    "\toutput_pickle_path = '../../iot_data_baseline.pkl'\n",
    "\tdns_pickle_path = '../../dns_data_baseline.pkl' \n",
    "\n",
    "\t# Create an object of IoTPcapReader\n",
    "\tiot_reader = IoTPcapReader(dataset_folder_path)\n",
    "\n",
    "# \t# Read all pcap files and store data in the dataframe\n",
    "# \tiot_reader.read_all_pcap_files()\n",
    "\n",
    "# \t# Save the dataframe as a pickle file\n",
    "# \tiot_reader.save_as_pickle(output_pickle_path)\n",
    "\n",
    "\t# Load and check the pickle file\n",
    "\tiot_reader.load_pickle(output_pickle_path)\n",
    "\tprint(iot_reader.global_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851b26a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\": \"packets-2025-01-05\", \"_type\": \"pcap_file\", \"_score\": null, \"_source\": {\"layers\": {\"frame\": {\"frame.encap_type\": \"1\", \"frame.time\": \"Nov 22, 2024 10:38:41.949893000 CET\", \"frame.offset_shift\": \"0.000000000\", \"frame.time_epoch\": \"1732268321.949893000\", \"frame.time_delta\": \"0.000000000\", \"frame.time_delta_displayed\": \"0.000000000\", \"frame.time_relative\": \"0.000000000\", \"frame.number\": \"1\", \"frame.len\": \"88\", \"frame.cap_len\": \"88\", \"frame.marked\": \"0\", \"frame.ignored\": \"0\", \"frame.protocols\": \"eth:ethertype:ip:udp:dns\"}, \"eth\": {\"eth.dst\": \"28:e3:47:8e:cf:a8\", \"eth.dst_tree\": {\"eth.dst_resolved\": \"LiteonTe_8e:cf:a8\", \"eth.addr\": \"28:e3:47:8e:cf:a8\", \"eth.addr_resolved\": \"LiteonTe_8e:cf:a8\", \"eth.lg\": \"0\", \"eth.ig\": \"0\"}, \"eth.src\": \"fc:9c:98:11:71:a8\", \"eth.src_tree\": {\"eth.src_resolved\": \"fc:9c:98:11:71:a8\", \"eth.addr\": \"fc:9c:98:11:71:a8\", \"eth.addr_resolved\": \"fc:9c:98:11:71:a8\", \"eth.lg\": \"0\", \"eth.ig\": \"0\"}, \"eth.type\": \"0x00000800\"}, \"ip\": {\"ip.version\": \"4\", \"ip.hdr_len\": \"20\", \"ip.dsfield\": \"0x00000000\", \"ip.dsfield_tree\": {\"ip.dsfield.dscp\": \"0\", \"ip.dsfield.ecn\": \"0\"}, \"ip.len\": \"74\", \"ip.id\": \"0x00002e99\", \"ip.flags\": \"0x00000000\", \"ip.flags_tree\": {\"ip.flags.rb\": \"0\", \"ip.flags.df\": \"0\", \"ip.flags.mf\": \"0\", \"ip.frag_offset\": \"0\"}, \"ip.ttl\": \"255\", \"ip.proto\": \"17\", \"ip.checksum\": \"0x000080e0\", \"ip.checksum.status\": \"2\", \"ip.src\": \"10.10.0.30\", \"ip.addr\": \"1.1.1.1\", \"ip.src_host\": \"10.10.0.30\", \"ip.host\": \"1.1.1.1\", \"ip.dst\": \"1.1.1.1\", \"ip.dst_host\": \"1.1.1.1\"}, \"udp\": {\"udp.srcport\": \"49564\", \"udp.dstport\": \"53\", \"udp.port\": \"53\", \"udp.length\": \"54\", \"udp.checksum\": \"0x00001428\", \"udp.checksum.status\": \"2\", \"udp.stream\": \"0\"}, \"dns\": {\"dns.id\": \"0x00000000\", \"dns.flags\": \"0x00000100\", \"dns.flags_tree\": {\"dns.flags.response\": \"0\", \"dns.flags.opcode\": \"0\", \"dns.flags.truncated\": \"0\", \"dns.flags.recdesired\": \"1\", \"dns.flags.z\": \"0\", \"dns.flags.checkdisable\": \"0\"}, \"dns.count.queries\": \"1\", \"dns.count.answers\": \"0\", \"dns.count.auth_rr\": \"0\", \"dns.count.add_rr\": \"0\", \"Queries\": {\"deviceapi.messaging.arlo.com: type A, class IN\": {\"dns.qry.name\": \"deviceapi.messaging.arlo.com\", \"dns.qry.name.len\": \"28\", \"dns.count.labels\": \"4\", \"dns.qry.type\": \"1\", \"dns.qry.class\": \"0x00000001\"}}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(iot_reader.global_dataframe[\"Packet JSON\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5dc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device Name  \\\n",
      "0           arlo_camera_pro4   \n",
      "1           arlo_camera_pro4   \n",
      "2           arlo_camera_pro4   \n",
      "3           arlo_camera_pro4   \n",
      "4           arlo_camera_pro4   \n",
      "...                      ...   \n",
      "712977  switchbot_hub_mini_2   \n",
      "712978  switchbot_hub_mini_2   \n",
      "712979  switchbot_hub_mini_2   \n",
      "712980  switchbot_hub_mini_2   \n",
      "712981  switchbot_hub_mini_2   \n",
      "\n",
      "                                              Packet JSON  \n",
      "0       {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "1       {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "2       {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "3       {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "4       {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "...                                                   ...  \n",
      "712977  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "712978  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "712979  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "712980  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "712981  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...  \n",
      "\n",
      "[712982 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(iot_reader.global_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a3a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# def expand_packet_json(global_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "# \t\"\"\"\n",
    "# \tExpand the 'Packet JSON' column in the global dataframe into individual columns.\n",
    "\n",
    "# \tArgs:\n",
    "# \t\tglobal_dataframe (pd.DataFrame): The dataframe containing the 'Packet JSON' column.\n",
    "\n",
    "# \tReturns:\n",
    "# \t\tpd.DataFrame: A new dataframe with individual fields from the JSON.\n",
    "# \t\"\"\"\n",
    "# \texpanded_data = []\n",
    "\n",
    "# \tfor _, row in global_dataframe.iterrows():\n",
    "# \t\tpacket_json = json.loads(row.get('Packet JSON', '{}'))\n",
    "# \t\tlayers = packet_json.get(\"_source\", {}).get(\"layers\", {})\n",
    "\n",
    "# \t\t# Flattening the nested structure into individual columns\n",
    "# \t\texpanded_row = {\n",
    "# \t\t\t\"Device Name\": row.get(\"Device Name\", \"\"),\n",
    "# \t\t\t\"Frame Time\": layers.get(\"frame\", {}).get(\"frame.time\", \"\"),\n",
    "# \t\t\t\"Frame Number\": layers.get(\"frame\", {}).get(\"frame.number\", \"\"),\n",
    "# \t\t\t\"Frame Length\": layers.get(\"frame\", {}).get(\"frame.len\", \"\"),\n",
    "# \t\t\t\"Source MAC\": layers.get(\"eth\", {}).get(\"eth.src\", \"\"),\n",
    "# \t\t\t\"Destination MAC\": layers.get(\"eth\", {}).get(\"eth.dst\", \"\"),\n",
    "# \t\t\t\"Source IP\": layers.get(\"ip\", {}).get(\"ip.src\", \"\"),\n",
    "# \t\t\t\"Destination IP\": layers.get(\"ip\", {}).get(\"ip.dst\", \"\"),\n",
    "# \t\t\t\"Protocol\": layers.get(\"frame\", {}).get(\"frame.protocols\", \"\"),\n",
    "# \t\t\t\"TCP Sequence Number\": layers.get(\"tcp\", {}).get(\"tcp.seq\", \"\"),\n",
    "# \t\t\t\"UDP Length\": layers.get(\"udp\", {}).get(\"udp.length\", \"\"),\n",
    "# \t\t\t\"DNS Transaction ID\": layers.get(\"dns\", {}).get(\"dns.id\", \"\"),\n",
    "# \t\t\t\"DNS Flags\": layers.get(\"dns\", {}).get(\"dns.flags\", \"\"),\n",
    "# \t\t\t\"DNS Query Name\": layers.get(\"dns.qry\", {}).get(\"dns.qry.name\", \"\"),\n",
    "# \t\t\t\"DNS Answer Name\": layers.get(\"dns.resp\", {}).get(\"dns.resp.name\", \"\"),\n",
    "# \t\t\t\"DNS Answer Address\": layers.get(\"dns.resp\", {}).get(\"dns.a\", \"\")\n",
    "# \t\t}\n",
    "\n",
    "# \t\texpanded_data.append(expanded_row)\n",
    "\n",
    "# \texpanded_df = pd.DataFrame(expanded_data)\n",
    "# \treturn expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59337dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a global_dataframe with the \"Packet JSON\" column:\n",
    "# expanded_df = expand_packet_json(iot_reader.global_dataframe)\n",
    "# print(expanded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e77d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "\n",
    "class DNSPacketAnalyzer:\n",
    "\tdef __init__(self, global_dataframe: pd.DataFrame, output_folder: str = './dns_analysis_plots'):\n",
    "\t\tself.df = global_dataframe\n",
    "\t\tself.output_folder = output_folder\n",
    "\t\tos.makedirs(self.output_folder, exist_ok=True)\n",
    "\t\tself.preprocessed_df = None\n",
    "\n",
    "\tdef preprocess_dns_packets(self):\n",
    "\t\tdns_records = []\n",
    "\n",
    "\t\tfor _, row in self.df.iterrows():\n",
    "\t\t\tpacket_json = json.loads(row.get('Packet JSON', '{}'))\n",
    "\t\t\tsource = packet_json.get('_source', {})\n",
    "\t\t\tlayers = source.get('layers', {})\n",
    "\t\t\tframe = layers.get('frame', {})\n",
    "\t\t\tdns = layers.get('dns', {})\n",
    "\t\t\tdns_flags = dns.get('dns.flags_tree', {})\n",
    "\n",
    "\t\t\tprotocols = frame.get('frame.protocols', ' ')\n",
    "\t\t\tis_dns = 'dns' in protocols\n",
    "\n",
    "\t\t\tif is_dns:\n",
    "\t\t\t\trecord = {\n",
    "\t\t\t\t\t'Device Name': row['Device Name'].replace('_', ''),\n",
    "\t\t\t\t\t'frame_time': frame.get('frame.time', ''),\n",
    "\t\t\t\t\t'frame_len': int(frame.get('frame.len', 0)) if frame.get('frame.len', '').isdigit() else 0,\n",
    "\t\t\t\t\t'protocols': protocols,\n",
    "\t\t\t\t\t'is_response': dns_flags.get('dns.flags.response', '') == '1',\n",
    "\t\t\t\t\t'queries': dns.get('Queries', {}),\n",
    "\t\t\t\t\t'answers': dns.get('Answers', {}),\n",
    "\t\t\t\t\t'edns': dns.get('dns.opt', ''),\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\trecord['ttl_list'] = [int(a.get('dns.resp.ttl', 0)) for a in record['answers'].values()] if record['answers'] else []\n",
    "\t\t\t\trecord['query_types'] = [q.get('dns.qry.type', '') for q in record['queries'].values()] if record['queries'] else []\n",
    "\t\t\t\trecord['query_names'] = [q.get('dns.qry.name', '') for q in record['queries'].values()] if record['queries'] else []\n",
    "\n",
    "\t\t\t\tdns_records.append(record)\n",
    "\n",
    "\t\tself.preprocessed_df = pd.DataFrame(dns_records)\n",
    "\t\tprint(f\"Preprocessed {len(self.preprocessed_df)} DNS packets.\")\n",
    "\n",
    "\tdef plot_bar(self, df, x, y, title, ylabel, filename, log_scale=False):\n",
    "\t\tplt.figure(figsize=(3.33, 2.2))\n",
    "\t\tplt.bar(df[x], df[y], width=0.6)\n",
    "\t\tif log_scale:\n",
    "\t\t\tplt.yscale('log')\n",
    "\t\tplt.xlabel(x, fontsize=7)\n",
    "\t\tplt.ylabel(ylabel, fontsize=7)\n",
    "# \t\tplt.title(title, fontsize=7)\n",
    "\t\tplt.xticks(rotation=45, ha='right', fontsize=5.5)\n",
    "\t\tplt.yticks(fontsize=6)\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.savefig(os.path.join(self.output_folder, filename), bbox_inches='tight', dpi=300)\n",
    "\t\tplt.close()\n",
    "\t\t\n",
    "\t\t# Save DataFrame + metadata as pickle\n",
    "\t\tpickle_data = {\n",
    "\t\t\t\"df\": df,\n",
    "\t\t\t\"x\": x,\n",
    "\t\t\t\"y\": y\n",
    "\t\t}\n",
    "\t\tpickle_path = os.path.join(self.output_folder, filename) + '.pkl'\n",
    "\t\twith open(pickle_path, 'wb') as f:\n",
    "\t\t\tpickle.dump(pickle_data, f)\n",
    "\n",
    "\tdef plot_dns_query_counts(self):\n",
    "\t\tsummary = self.preprocessed_df.groupby('Device Name').size().reset_index(name='Number of Queries')\n",
    "\t\tself.plot_bar(summary, 'Device Name', 'Number of Queries', 'DNS Queries per Device', 'Queries', 'dns_query_counts.pdf')\n",
    "\n",
    "\tdef plot_average_ttl(self):\n",
    "\t\texploded = self.preprocessed_df.explode('ttl_list')\n",
    "\t\texploded = exploded[exploded['ttl_list'] > 0]\n",
    "\t\tsummary = exploded.groupby('Device Name')['ttl_list'].mean().reset_index()\n",
    "\t\tself.plot_bar(summary, 'Device Name', 'ttl_list', 'Average TTL per Device', 'Avg. TTL (log, s)', 'average_ttl_log.pdf', log_scale=True)\n",
    "\n",
    "\tdef plot_dns_answer_counts(self):\n",
    "\t\tsummary = self.preprocessed_df.explode('answers').groupby('Device Name').size().reset_index(name='Number of Answers')\n",
    "\t\tself.plot_bar(summary, 'Device Name', 'Number of Answers', 'DNS Answers per Device', 'DNS Answers', 'dns_answer_counts.pdf')\n",
    "\n",
    "\tdef plot_dns_query_types(self):\n",
    "\t\tquery_types = self.preprocessed_df.explode('query_names')\n",
    "\t\tcounts = query_types.groupby(['Device Name', 'query_names']).size().reset_index(name='Count')\n",
    "\t\tpivot = counts.pivot(index='Device Name', columns='query_names', values='Count').fillna(0)\n",
    "\t\tax = pivot.plot(kind='bar', stacked=True, figsize=(3.33, 2.5), width=0.6)\n",
    "\t\tplt.xlabel('Device Name', fontsize=7)\n",
    "\t\tplt.ylabel('Query Count', fontsize=7)\n",
    "# \t\tplt.title('DNS Query Types per Device', fontsize=7)\n",
    "\t\tplt.xticks(rotation=45, ha='right', fontsize=6)\n",
    "\t\tplt.yticks(fontsize=6)\n",
    "\t\tplt.legend(fontsize=5, loc='upper right', frameon=False)\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.savefig(os.path.join(self.output_folder, 'dns_query_types.pdf'), bbox_inches='tight', dpi=300)\n",
    "\t\tplt.close()\n",
    "\n",
    "\tdef plot_avg_time_between_queries(self):\n",
    "\t\ttimes = self.preprocessed_df[~self.preprocessed_df['is_response']]\n",
    "\t\ttimes['parsed_time'] = pd.to_datetime(times['frame_time'], errors='coerce')\n",
    "\t\ttimes = times.dropna(subset=['parsed_time'])\n",
    "\t\tavg_times = times.sort_values('parsed_time').groupby('Device Name')['parsed_time'].apply(lambda x: x.diff().mean().total_seconds() if len(x) > 1 else 0).reset_index(name='Avg Time Between Queries')\n",
    "\t\tself.plot_bar(avg_times, 'Device Name', 'Avg Time Between Queries', 'Avg. Time Between DNS Queries', 'Avg. Time (log, s)', 'avg_time_between_queries_log.pdf', log_scale=True)\n",
    "\n",
    "\tdef plot_distinct_addresses(self):\n",
    "\t\taddr_df = self.preprocessed_df.explode('answers')\n",
    "\t\taddr_df['dns_a'] = addr_df['answers'].apply(lambda a: a.get('dns.a') if isinstance(a, dict) else None)\n",
    "\t\tdistinct_counts = addr_df.dropna(subset=['dns_a']).groupby('Device Name')['dns_a'].nunique().reset_index(name='Distinct Addresses')\n",
    "\t\tself.plot_bar(distinct_counts, 'Device Name', 'Distinct Addresses', 'Distinct DNS Addresses per Device', 'Distinct Addr.', 'distinct_addresses.pdf')\n",
    "\n",
    "\tdef plot_avg_answers_per_frame(self):\n",
    "\t\tans_df = self.preprocessed_df.copy()\n",
    "\t\tans_df['answer_count'] = ans_df['answers'].apply(lambda a: len(a) if isinstance(a, dict) else 0)\n",
    "\t\tavg_ans = ans_df.groupby('Device Name')['answer_count'].mean().reset_index(name='Answers per Frame')\n",
    "\t\tself.plot_bar(avg_ans, 'Device Name', 'Answers per Frame', 'Avg. DNS Answers per Frame', 'Avg. Answers / Frame', 'average_answers_per_frame.pdf')\n",
    "\n",
    "\tdef calculate_ipv6_query_percentage(self):\n",
    "\t\tipv6_df = self.preprocessed_df.explode('query_types')\n",
    "\t\ttotal_counts = ipv6_df.groupby('Device Name').size()\n",
    "\t\tipv6_counts = ipv6_df[ipv6_df['query_types'] == '28'].groupby('Device Name').size()\n",
    "\t\tpercent_df = (ipv6_counts / total_counts * 100).fillna(0).reset_index(name='IPv6 Query Percentage')\n",
    "\t\tself.plot_bar(percent_df, 'Device Name', 'IPv6 Query Percentage', 'IPv6 Queries per Device', 'IPv6 Query %', 'ipv6_query_percentage.pdf')\n",
    "\n",
    "\tdef calculate_average_retries(self):\n",
    "\t\tretries_df = self.preprocessed_df.explode('query_names')\n",
    "\t\tretries_count = retries_df.groupby(['Device Name', 'query_names']).size().reset_index(name='count')\n",
    "\t\tavg_retries = retries_count[retries_count['count'] > 1].groupby('Device Name')['count'].mean().reset_index(name='Average Retries')\n",
    "\t\tself.plot_bar(avg_retries, 'Device Name', 'Average Retries', 'Avg. DNS Query Retries per Device', 'Avg. Retries', 'average_dns_retries.pdf')\n",
    "\n",
    "\tdef plot_query_rate(self):\n",
    "\t\ttimes = self.preprocessed_df[~self.preprocessed_df['is_response']]\n",
    "\t\ttimes['parsed_time'] = pd.to_datetime(times['frame_time'], errors='coerce')\n",
    "\t\trate_df = times.dropna(subset=['parsed_time']).groupby('Device Name').apply(lambda x: len(x) / (x['parsed_time'].max() - x['parsed_time'].min()).total_seconds() if len(x) > 1 else 0).reset_index(name='Query Rate (queries/sec)')\n",
    "\t\tself.plot_bar(rate_df, 'Device Name', 'Query Rate (queries/sec)', 'DNS Query Rate per Device', 'Queries/sec', 'query_rate.pdf')\n",
    "\n",
    "\tdef plot_protocol_distribution(self):\n",
    "\t\tproto_counts = defaultdict(lambda: defaultdict(int))\n",
    "\t\tfor _, row in self.df.iterrows():\n",
    "\t\t\tdevice = row['Device Name']\n",
    "\t\t\tpacket_json = json.loads(row.get('Packet JSON', '{}'))\n",
    "\t\t\tprotocols = packet_json.get('_source', {}).get('layers', {}).get('frame', {}).get('frame.protocols', '')\n",
    "\t\t\tfor proto in protocols.split(':'):\n",
    "\t\t\t\tproto_counts[device][proto] += 1\n",
    "\t\tproto_df = pd.DataFrame(proto_counts).fillna(0).T\n",
    "\t\tax = proto_df.plot(kind='bar', stacked=True, figsize=(3.33, 2.5), width=0.6)\n",
    "\t\tplt.xlabel('Device Name', fontsize=7)\n",
    "\t\tplt.ylabel('Packet Count', fontsize=7)\n",
    "\t\tplt.yscale('log')\n",
    "# \t\tplt.title('Protocol Distribution per Device', fontsize=7)\n",
    "\t\tplt.xticks(rotation=45, ha='right', fontsize=6)\n",
    "\t\tplt.yticks(fontsize=6)\n",
    "\t\tplt.legend(title='Protocols', fontsize=5, title_fontsize=6, bbox_to_anchor=(1.05, 1), ncols=4, frameon=False)\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.savefig(os.path.join(self.output_folder, 'protocol_distribution.pdf'), bbox_inches='tight', dpi=300)\n",
    "\t\tplt.close()\n",
    "\n",
    "\tdef plot_mdns_count(self):\n",
    "\t\tmdns_df = self.preprocessed_df[self.preprocessed_df['protocols'].str.lower().str.contains('mdns')]\n",
    "\t\tsummary = mdns_df.groupby('Device Name').size().reset_index(name='MDNS Count')\n",
    "\t\tself.plot_bar(summary, 'Device Name', 'MDNS Count', 'MDNS Packet Count per Device', 'MDNS Packets', 'mdns_count.pdf')\n",
    "\n",
    "\tdef analyze_dns_query_context(self, time_window=5):\n",
    "\t\tself.df['Device Name'] = self.df['Device Name'].str.replace('_', ' ', regex=False)\n",
    "\t\tself.preprocessed_df['Device Name'] = self.preprocessed_df['Device Name'].str.replace('_', ' ', regex=False)\n",
    "\n",
    "\t\tself.df['Timestamp'] = self.df['Packet JSON'].apply(\n",
    "\t\t\tlambda x: parser.parse(json.loads(x).get('_source', {}).get('layers', {}).get('frame', {}).get('frame.time', '')) if x else None)\n",
    "\t\tself.preprocessed_df['Timestamp'] = self.preprocessed_df['frame_time'].apply(\n",
    "\t\t\tlambda x: parser.parse(x) if x else None)\n",
    "\n",
    "\t\tquery_contexts = []\n",
    "\t\ttraffic_context_count = {}\n",
    "\n",
    "\t\tfor _, dns_row in self.preprocessed_df.iterrows():\n",
    "\t\t\tdns_time = dns_row['Timestamp']\n",
    "\t\t\tdevice_name = dns_row['Device Name']\n",
    "\t\t\tdns_query = dns_row['queries']\n",
    "\n",
    "\t\t\tif dns_query:\n",
    "\t\t\t\tdns_query_name = list(dns_query.values())[0].get('dns.qry.name', '')\n",
    "\n",
    "\t\t\t\trelated_packets = self.df[\n",
    "\t\t\t\t\t(self.df['Device Name'] == device_name) &\n",
    "\t\t\t\t\t(self.df['Timestamp'] >= dns_time - pd.Timedelta(seconds=time_window)) &\n",
    "\t\t\t\t\t(self.df['Timestamp'] <= dns_time + pd.Timedelta(seconds=time_window))\n",
    "\t\t\t\t]\n",
    "\n",
    "\t\t\t\treasons = []\n",
    "\n",
    "\t\t\t\tfor _, packet in related_packets.iterrows():\n",
    "\t\t\t\t\tpacket_json = json.loads(packet['Packet JSON'])\n",
    "\t\t\t\t\tprotocols = packet_json.get('_source', {}).get('layers', {}).get('frame', {}).get('frame.protocols', '')\n",
    "\n",
    "\t\t\t\t\tif 'tcp' in protocols and 'http' in protocols:\n",
    "\t\t\t\t\t\treasons.append(\"HTTP Request after DNS\")\n",
    "\t\t\t\t\telif 'tcp' in protocols and 'tcp.analysis.retransmission' in packet_json.get('_source', {}).get('layers', {}).get('tcp', {}):\n",
    "\t\t\t\t\t\treasons.append(\"TCP Retransmission before DNS\")\n",
    "\t\t\t\t\telif 'tcp' in protocols and 'tcp.flags.syn' in packet_json.get('_source', {}).get('layers', {}).get('tcp', {}):\n",
    "\t\t\t\t\t\treasons.append(\"TCP SYN before DNS\")\n",
    "\t\t\t\t\telif 'dhcp' in protocols:\n",
    "\t\t\t\t\t\treasons.append(\"DHCP before DNS\")\n",
    "\t\t\t\t\telif 'icmp' in protocols:\n",
    "\t\t\t\t\t\treasons.append(\"ICMP before DNS\")\n",
    "\t\t\t\t\telif 'quic' in protocols:\n",
    "\t\t\t\t\t\treasons.append(\"QUIC traffic near DNS\")\n",
    "\n",
    "\t\t\t\treasons = list(set(reasons))  # Remove duplicates\n",
    "\n",
    "\t\t\t\tquery_contexts.append({\n",
    "\t\t\t\t\t'Device Name': device_name,\n",
    "\t\t\t\t\t'DNS Query': dns_query_name,\n",
    "\t\t\t\t\t'Query Time': dns_time,\n",
    "\t\t\t\t\t'Traffic Context': ', '.join(reasons) if reasons else \"Unknown\"\n",
    "\t\t\t\t})\n",
    "\n",
    "\t\t\t\tfor reason in reasons:\n",
    "\t\t\t\t\tif device_name not in traffic_context_count:\n",
    "\t\t\t\t\t\ttraffic_context_count[device_name] = {}\n",
    "\t\t\t\t\tif reason not in traffic_context_count[device_name]:\n",
    "\t\t\t\t\t\ttraffic_context_count[device_name][reason] = 0\n",
    "\t\t\t\t\ttraffic_context_count[device_name][reason] += 1\n",
    "\n",
    "\t\tquery_context_df = pd.DataFrame(query_contexts)\n",
    "\t\tquery_context_df.to_csv(os.path.join(self.output_folder, 'dns_query_context.csv'), index=False)\n",
    "\t\tprint(\"DNS query context analysis completed. Results saved in 'dns_query_context.csv'.\")\n",
    "\n",
    "\t\tself.plot_traffic_context_distribution(traffic_context_count)\n",
    "\n",
    "\t\treturn query_context_df\n",
    "\n",
    "\tdef plot_traffic_context_distribution(self, traffic_context_count):\n",
    "\t\tmatplotlib.rcParams.update({'font.size': 7})  # ACM small font\n",
    "\t\tdata = []\n",
    "\t\tfor device, reasons in traffic_context_count.items():\n",
    "\t\t\tfor reason, count in reasons.items():\n",
    "\t\t\t\tdata.append({'Device Name': device, 'Traffic Context': reason, 'Count': count})\n",
    "\n",
    "\t\tdf = pd.DataFrame(data)\n",
    "\t\tpivot_df = df.pivot(index='Device Name', columns='Traffic Context', values='Count').fillna(0)\n",
    "\t\tax = pivot_df.plot(kind='bar', stacked=True, figsize=(3.33, 2.5), width=0.6)\n",
    "\t\tplt.xlabel('Device Name', fontsize=7)\n",
    "\t\tplt.ylabel('Context Count', fontsize=7)\n",
    "# \t\tplt.title('Traffic Contexts Around DNS Queries', fontsize=7)\n",
    "\t\tplt.xticks(rotation=45, ha='right', fontsize=5.5)\n",
    "\t\tplt.yticks(fontsize=6)\n",
    "\t\tplt.legend(fontsize=5, bbox_to_anchor=(0.5, 1.30), ncols=2, frameon=False)\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.savefig(os.path.join(self.output_folder, 'traffic_context_distribution.pdf'), bbox_inches='tight', dpi=300)\n",
    "\t\tplt.close()\n",
    "\t\tprint(\"Traffic context distribution plot saved.\")\n",
    "\n",
    "\tdef plot_edns0_usage(self):\n",
    "\t\tedns_df = self.preprocessed_df[self.preprocessed_df['edns'] != '']\n",
    "\t\tsummary = edns_df.groupby('Device Name').size().reset_index(name='EDNS(0) Count')\n",
    "\t\tself.plot_bar(summary, 'Device Name', 'EDNS(0) Count', 'EDNS(0) Usage per Device', 'EDNS(0) Count', 'edns0_usage.pdf')\n",
    "\n",
    "\tdef analyze(self):\n",
    "\t\tself.preprocess_dns_packets()\n",
    "\t\tif not self.preprocessed_df.empty:\n",
    "\t\t\tself.plot_dns_query_counts()\n",
    "\t\t\tself.plot_average_ttl()\n",
    "\t\t\tself.plot_dns_answer_counts()\n",
    "\t\t\tself.plot_dns_query_types()\n",
    "# \t\t\tself.plot_avg_time_between_queries()\n",
    "\t\t\tself.plot_distinct_addresses()\n",
    "\t\t\tself.plot_avg_answers_per_frame()\n",
    "\t\t\tself.calculate_ipv6_query_percentage()\n",
    "\t\t\tself.calculate_average_retries()\n",
    "# \t\t\tself.plot_query_rate()\n",
    "\t\t\tself.analyze_dns_query_context()\n",
    "\t\t\tself.plot_protocol_distribution()\n",
    "\t\t\tself.plot_mdns_count()\n",
    "# \t\t\tself.plot_edns0_usage()\n",
    "\t\t\tprint(f\"All plots saved to {self.output_folder}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(\"No DNS packets found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90af175a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 6024 DNS packets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_995395/2963476988.py:101: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS query context analysis completed. Results saved in 'dns_query_context.csv'.\n",
      "Traffic context distribution plot saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_995395/2963476988.py:160: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All plots saved to ./dns_analysis_plots\n"
     ]
    }
   ],
   "source": [
    "# Assuming iot_reader.global_dataframe is already populated\n",
    "dns_analyzer = DNSPacketAnalyzer(iot_reader.global_dataframe)\n",
    "\n",
    "# Perform DNS analysis and generate/save plots\n",
    "dns_analyzer.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8355e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from pickle at ../../iot_data_doh.pkl\n",
      "        Device Name                                        Packet JSON\n",
      "0  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "1  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "2  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "3  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n",
      "4  arlo_camera_pro4  {\"_index\": \"packets-2025-01-05\", \"_type\": \"pca...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t# Example usage:\n",
    "\tdataset_folder_path = '../../DOH'\n",
    "\toutput_pickle_path = '../../iot_data_doh.pkl'\n",
    "\tdns_pickle_path = '../../dns_data_doh.pkl' \n",
    "\n",
    "\t# Create an object of IoTPcapReader\n",
    "\tiot_reader2 = IoTPcapReader(dataset_folder_path)\n",
    "\n",
    "# \t# Read all pcap files and store data in the dataframe\n",
    "# \tiot_reader.read_all_pcap_files()\n",
    "\n",
    "# \t# Save the dataframe as a pickle file\n",
    "# \tiot_reader.save_as_pickle(output_pickle_path)\n",
    "\n",
    "\t# Load and check the pickle file\n",
    "\tiot_reader2.load_pickle(output_pickle_path)\n",
    "\tprint(iot_reader2.global_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c843f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 35563 DNS packets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_995395/2963476988.py:101: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS query context analysis completed. Results saved in 'dns_query_context.csv'.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Device Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m dns_analyzer2 \u001b[38;5;241m=\u001b[39m DNSPacketAnalyzer(iot_reader2\u001b[38;5;241m.\u001b[39mglobal_dataframe, output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dns_analysis_plots_doh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Perform DNS analysis and generate/save plots\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdns_analyzer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mDNSPacketAnalyzer.analyze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \t\t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_average_retries()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# \t\t\tself.plot_query_rate()\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m \t\t\t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_dns_query_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \t\t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_protocol_distribution()\n\u001b[1;32m    279\u001b[0m \t\t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_mdns_count()\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mDNSPacketAnalyzer.analyze_dns_query_context\u001b[0;34m(self, time_window)\u001b[0m\n\u001b[1;32m    231\u001b[0m query_context_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdns_query_context.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDNS query context analysis completed. Results saved in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdns_query_context.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_traffic_context_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraffic_context_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_context_df\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mDNSPacketAnalyzer.plot_traffic_context_distribution\u001b[0;34m(self, traffic_context_count)\u001b[0m\n\u001b[1;32m    243\u001b[0m \t\tdata\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevice Name\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraffic Context\u001b[39m\u001b[38;5;124m'\u001b[39m: reason, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m: count})\n\u001b[1;32m    245\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m--> 246\u001b[0m pivot_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDevice Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraffic Context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    247\u001b[0m ax \u001b[38;5;241m=\u001b[39m pivot_df\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, stacked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3.33\u001b[39m, \u001b[38;5;241m2.5\u001b[39m), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m    248\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevice Name\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
      "File \u001b[0;32m/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\n\u001b[1;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:553\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    549\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    550\u001b[0m             data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    551\u001b[0m         ]\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [data[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[1;32m    555\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    556\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:553\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    550\u001b[0m             data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    551\u001b[0m         ]\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[1;32m    555\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    556\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/home/tribe/mabhishe/myspace/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Device Name'"
     ]
    }
   ],
   "source": [
    "# Assuming iot_reader.global_dataframe is already populated\n",
    "dns_analyzer2 = DNSPacketAnalyzer(iot_reader2.global_dataframe, output_folder = './dns_analysis_plots_doh')\n",
    "\n",
    "# Perform DNS analysis and generate/save plots\n",
    "dns_analyzer2.analyze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
